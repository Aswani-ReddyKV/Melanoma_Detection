{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aswani-ReddyKV/Melanoma_Detection/blob/main/aswani_reddy_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDriIbfa5lwD"
      },
      "source": [
        "Problem statement: To build a CNN based model which can accurately detect melanoma. Melanoma is a type of cancer that can be deadly if not detected early. It accounts for 75% of skin cancer deaths. A solution which can evaluate images and alert the dermatologists about the presence of melanoma has the potential to reduce a lot of manual effort needed in diagnosis."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pathlib\n",
        "# import tensorflow as tf\n",
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import os\n",
        "# from glob import glob\n",
        "# import PIL\n",
        "# from tensorflow import keras\n",
        "# from tensorflow.keras import layers\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.python.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPool2D\n",
        "# from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Conv2D, MaxPooling2D\n",
        "# from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img,img_to_array"
      ],
      "metadata": {
        "id": "WLtpSFO-w6Tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pathlib\n",
        "import pandas as pd\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "HrUhOSn592NJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "OBRBuROGspvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rootfolder = '/content/drive/MyDrive/Colab Notebooks/SkinCancer_Data'\n",
        "train_dir = pathlib.Path(rootfolder + '/Train')\n",
        "test_dir = pathlib.Path(rootfolder + '/Test')"
      ],
      "metadata": {
        "id": "ng1xGfyPwc26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the number of images present in Train directory\n",
        "train_img_count = len(list(train_dir.glob('*/*.jpg')))\n",
        "print(\"Total Images(Train):\",train_img_count)"
      ],
      "metadata": {
        "id": "iKnp8LyuyIsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the number of images present in Test directory\n",
        "test_img_count = len(list(test_dir.glob('*/*.jpg')))\n",
        "print(\"Total Images(Test):\",test_img_count)"
      ],
      "metadata": {
        "id": "Wj9Y4PYA6dpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define parameters for loader"
      ],
      "metadata": {
        "id": "lvo2S3eI7jI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch size\n",
        "batch_size = 32\n",
        "# image height\n",
        "img_height = 180\n",
        "# image width\n",
        "img_width = 180"
      ],
      "metadata": {
        "id": "x67AGWtx7ren"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use 80% of the images for training and 20% for validation.\n",
        "Creating two separate sets for Train and Validation."
      ],
      "metadata": {
        "id": "_vFlOsyk7y_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split dataset for train\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  train_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "ALsKgQnI7nRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split dataset for validation\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  train_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "kvIdtFsD7_-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get class names\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "x2iraiBk8FS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(class_names)"
      ],
      "metadata": {
        "id": "4l3lin2v-Rc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datalist =[]\n",
        "for c in class_names:\n",
        "  lst = os.listdir(pathlib.Path(train_dir / c)) # use / to join paths\n",
        "  number_files = len(lst)\n",
        "  datalist.append([c, number_files])\n",
        "df = pd.DataFrame(datalist, columns=['Class', 'Count'])"
      ],
      "metadata": {
        "id": "bqz2lDko0l9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize the Number of image in each class.\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.barplot(x=\"Count\", y=\"Class\", data=df, palette='copper_r')"
      ],
      "metadata": {
        "id": "5TK9P_2I3vE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `image_batch` is a tensor of the shape `(32, 180, 180, 3)`. This is a batch of 32 images of shape `180x180x3` (the last dimension refers to color channels RGB). The `label_batch` is a tensor of the shape `(32,)`, these are corresponding labels to the 32 images."
      ],
      "metadata": {
        "id": "QSxAqqXb6vrj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Dataset.cache()` keeps the images in memory after they're loaded off disk during the first epoch.\n",
        "\n",
        "`Dataset.prefetch()` overlaps data preprocessing and model execution while training."
      ],
      "metadata": {
        "id": "LKyLPoKG6w-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "ufqXdBf16zka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the model\n",
        "####Create a CNN model, which can accurately detect 9 classes present in the dataset. Use ```layers.experimental.preprocessing.Rescaling``` to normalize pixel values between (0,1). The RGB channel values are in the `[0, 255]` range. This is not ideal for a neural network. Here, it is good to standardize values to be in the `[0, 1]`"
      ],
      "metadata": {
        "id": "D_I7AKBt656J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (180,180,3)\n",
        "lr = 1e-5\n",
        "init = 'normal'\n",
        "activ = 'relu'\n",
        "\n",
        "model = Sequential()\n",
        "model.add(tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(180, 180, 3)))\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n"
      ],
      "metadata": {
        "id": "Y1LyF6fz660Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compile the model\n",
        "Choose an appropirate optimiser and loss function for model training"
      ],
      "metadata": {
        "id": "CMTvYkynBePs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compile\n",
        "optimizer = 'adam'\n",
        "loss_fn = \"binary_crossentropy\"\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "fzPNEMh0Bt6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View the summary of all layers\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "lUcE8n5cB3QY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the model"
      ],
      "metadata": {
        "id": "pxBDqzoVDPpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "epochs = 20\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "7OV9SP3jDLLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing training results"
      ],
      "metadata": {
        "id": "vMEOmUWuDS-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KqDfOYZtDVhc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}